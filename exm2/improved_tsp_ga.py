import numpy as np
import matplotlib.pyplot as plt
from exm2 import distance, cities, distance_matrix, norm_path
from cross_lib import ox, pmx

"""
This script is generated by Claude 4.0 
"""

def tournament_selection(population, fitness, k=5):
    """
    Tournament selection - more effective than roulette wheel
    """
    n = len(population)
    selected = []
    
    for _ in range(len(population)):
        # Select k random individuals for tournament
        tournament_indices = np.random.choice(n, k, replace=False)
        # Select the best from tournament (lowest distance = highest fitness)
        winner_idx = tournament_indices[np.argmin(fitness[tournament_indices])]
        selected.append(population[winner_idx].copy())
    
    return np.array(selected)

def adaptive_mutation(individual, mutation_rate, generation, max_generations):
    """
    Adaptive mutation that decreases over time and uses different strategies
    """
    # Adaptive mutation rate
    adaptive_rate = mutation_rate * (1 - generation / max_generations)
    
    if np.random.random() < adaptive_rate:
        strategy = np.random.choice(['swap', 'insert', 'reverse'])
        
        if strategy == 'swap':
            # Swap two random cities
            i, j = np.random.choice(len(individual), 2, replace=False)
            individual[i], individual[j] = individual[j], individual[i]

        elif strategy == 'insert':
            # Remove a city and insert it elsewhere
            i = np.random.randint(len(individual))
            j = np.random.randint(len(individual))
            city = individual[i]
            individual = np.delete(individual, i)
            individual = np.insert(individual, j, city)
            
        elif strategy == 'reverse':
            # Reverse a segment
            i, j = sorted(np.random.choice(len(individual), 2, replace=False))
            individual[i:j+1] = individual[i:j+1][::-1]
    
    return individual

def local_search_2opt(tour, dist_matrix, max_improvements=10):
    """
    2-opt local search for tour improvement
    """
    best_tour = tour.copy()
    best_distance = distance(best_tour.reshape(1, -1), dist_matrix)[0]
    improvements = 0
    
    n = len(tour)
    for i in range(n):
        if improvements >= max_improvements:
            break
        for j in range(i + 2, n):
            if j == n - 1 and i == 0:  # Skip if it's the same edge
                continue
                
            # Create new tour by reversing segment between i and j
            new_tour = best_tour.copy()
            new_tour[i:j+1] = new_tour[i:j+1][::-1]
            
            new_distance = distance(new_tour.reshape(1, -1), dist_matrix)[0]
            
            if new_distance < best_distance:
                best_tour = new_tour
                best_distance = new_distance
                improvements += 1
    
    return best_tour

def improved_tsp(cities: np.ndarray,
                n_population=200,
                n_generations=500,
                mutation_rate=0.15,
                crossover_rate=0.85,
                elite_size=10,
                tournament_size=5,
                local_search_freq=50,
                convergence_threshold=100):
    """
    Improved TSP solver using Genetic Algorithm with multiple enhancements:
    
    Key Improvements:
    1. Tournament selection instead of roulette wheel
    2. Elitism with guaranteed best solution preservation
    3. Order crossover (OX) instead of PMX
    4. Adaptive mutation with multiple strategies
    5. Optional 2-opt local search
    6. Convergence detection
    7. Better fitness handling
    """
    n_cities = len(cities)
    
    # Initialize population with random permutations
    population = np.array([np.random.permutation(n_cities) for _ in range(n_population)], dtype=np.int32)
    
    # Normalize all paths
    for i in range(n_population):
        population[i] = norm_path(population[i])
    
    best_distance_history = []
    best_solution = None
    best_distance = float('inf')
    stagnation_counter = 0
    
    print(f"Starting TSP optimization with {n_cities} cities...")
    print(f"Population: {n_population}, Generations: {n_generations}")
    print(f"Elite size: {elite_size}, Tournament size: {tournament_size}")
    print("-" * 60)
    
    for generation in range(n_generations):
        # Calculate fitness (distances)
        distances = distance(population, distance_matrix)
        
        # Track best solution
        current_best_idx = np.argmin(distances)
        current_best_distance = distances[current_best_idx]
        
        if current_best_distance < best_distance:
            best_distance = current_best_distance
            best_solution = population[current_best_idx].copy()
            stagnation_counter = 0
            print(f"Generation {generation:4d}: New best distance = {best_distance:.2f}")
        else:
            stagnation_counter += 1
        
        best_distance_history.append(best_distance)
        
        # Check for convergence
        if stagnation_counter >= convergence_threshold:
            print(f"Converged after {generation} generations (no improvement for {convergence_threshold} generations)")
            break
        
        # Create next generation
        new_population = []
        
        # Elitism: Keep best solutions
        elite_indices = np.argsort(distances)[:elite_size]
        for idx in elite_indices:
            new_population.append(population[idx].copy())
        
        # Generate offspring
        while len(new_population) < n_population:
            # Tournament selection
            selected_population = tournament_selection(population, distances, tournament_size)
            
            # Crossover
            if np.random.random() < crossover_rate:
                parent1, parent2 = selected_population[np.random.choice(len(selected_population), 2, replace=False)]
                child1, child2 = ox(parent1, parent2)
            else:
                child1 = selected_population[np.random.randint(len(selected_population))]
                child2 = selected_population[np.random.randint(len(selected_population))]
            
            # Mutation
            child1 = adaptive_mutation(child1, mutation_rate, generation, n_generations)
            child2 = adaptive_mutation(child2, mutation_rate, generation, n_generations)
            
            # Normalize paths
            child1 = norm_path(child1)
            child2 = norm_path(child2)
            
            new_population.extend([child1, child2])
        
        # Trim population to exact size
        population = np.array(new_population[:n_population], dtype=np.int32)
        
        # Optional local search on best individuals
        if generation % local_search_freq == 0 and generation > 0:
            # Apply 2-opt to top 10% of population
            n_local_search = max(1, n_population // 10)
            current_distances = distance(population, distance_matrix)
            best_indices = np.argsort(current_distances)[:n_local_search]

            for idx in best_indices:
                improved_tour = local_search_2opt(population[idx], distance_matrix, max_improvements=5)
                population[idx] = improved_tour
        
        # Progress report every 50 generations
        if generation % 50 == 0:
            avg_distance = np.mean(distances)
            print(f"Generation {generation:4d}: Best = {best_distance:.2f}, "
                  f"Current avg = {avg_distance:.2f}, Stagnation = {stagnation_counter}")
    
    print("-" * 60)
    print(f"Optimization completed!")
    print(f"Best distance found: {best_distance:.2f}")
    print(f"Final generation: {generation}")
    
    # Plot convergence
    plt.figure(figsize=(12, 5))
    
    plt.subplot(1, 2, 1)
    plt.plot(best_distance_history)
    plt.title('Convergence History')
    plt.xlabel('Generation')
    plt.ylabel('Best Distance')
    plt.grid(True)
    
    plt.subplot(1, 2, 2)
    draw_path(cities, best_solution)
    
    plt.tight_layout()
    plt.show()
    
    return best_solution, best_distance, best_distance_history

def draw_path(cities, path):
    """Plot the TSP tour"""
    if cities is None:
        print("Cities data not available for plotting")
        return
        
    # Complete the tour by returning to start
    tour = np.append(path, path[0])
    plt.plot(cities[tour, 0], cities[tour, 1], '-o', color='steelblue', 
             markersize=6, linewidth=2, alpha=0.8)
    
    # Highlight start city
    plt.plot(cities[path[0], 0], cities[path[0], 1], 'ro', markersize=10, 
             label='Start City')
    
    # Add city numbers
    for i, (x, y) in enumerate(cities):
        plt.annotate(str(i), (x, y), xytext=(5, 5), textcoords='offset points', 
                    fontsize=8)
    
    plt.title(f'TSP Tour ({len(cities)} cities)')
    plt.xlabel('X Coordinate')
    plt.ylabel('Y Coordinate')
    plt.legend()
    plt.grid(True, alpha=0.3)
    plt.axis('equal')

# Example usage with synthetic data
def test_improved_algorithm():
    """Test the improved algorithm with synthetic city data"""
    np.random.seed(42)  # For reproducible results

    
    print("Testing improved TSP algorithm with synthetic data...")
    
    # Run optimization
    best_solution, best_distance, history = improved_tsp(
        cities,
        n_population=150,
        n_generations=300,
        mutation_rate=0.1,
        crossover_rate=0.9,
        elite_size=15,
        tournament_size=7,
        local_search_freq=25,
        convergence_threshold=50
    )
    
    print(f"\nBest tour: {best_solution}")
    print(f"Best distance: {best_distance:.2f}")
    
    return best_solution, best_distance

# Uncomment to test with synthetic data
if __name__ == '__main__':
    test_improved_algorithm()

# To use with your actual data:
# data = pd.read_csv("cities.csv", header=None).transpose()
# data.columns = ['x', 'y']
# cities = np.array(data)
# best_solution, best_distance, history = improved_tsp(cities)